{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install multimodal-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    set_seed\n",
    ")\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from multimodal_transformers.data import load_data_from_folder\n",
    "from multimodal_transformers.model import TabularConfig\n",
    "from multimodal_transformers.model import AutoModelWithTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Article Headline</th>\n",
       "      <th>Article URL</th>\n",
       "      <th>Article Text</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>Stock Open</th>\n",
       "      <th>Stock Close</th>\n",
       "      <th>Stock High</th>\n",
       "      <th>Stock Low</th>\n",
       "      <th>volume</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>US stocks fall, oil tops $105 as Ukraine crisi...</td>\n",
       "      <td>https://www.aljazeera.com/economy/2022/3/1/us-...</td>\n",
       "      <td>A surge in oil sent shivers through risky asse...</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>Somewhat-Bearish</td>\n",
       "      <td>164.695</td>\n",
       "      <td>163.20</td>\n",
       "      <td>166.60</td>\n",
       "      <td>161.97</td>\n",
       "      <td>79455454.0</td>\n",
       "      <td>701957.0</td>\n",
       "      <td>164.167482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>Rich Russians turn to luxury jewellery, watche...</td>\n",
       "      <td>https://www.aljazeera.com/economy/2022/3/2/ric...</td>\n",
       "      <td>With sanctions on Russia sending the ruble plu...</td>\n",
       "      <td>-0.118323</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>164.390</td>\n",
       "      <td>166.56</td>\n",
       "      <td>167.36</td>\n",
       "      <td>162.95</td>\n",
       "      <td>76135254.0</td>\n",
       "      <td>631927.0</td>\n",
       "      <td>165.810466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>Are You an Investor Needing Some Calm Guidance?</td>\n",
       "      <td>https://www.fool.com/investing/2022/03/03/are-...</td>\n",
       "      <td>Read this.</td>\n",
       "      <td>-0.041040</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>168.470</td>\n",
       "      <td>166.23</td>\n",
       "      <td>168.91</td>\n",
       "      <td>165.55</td>\n",
       "      <td>73779442.0</td>\n",
       "      <td>622341.0</td>\n",
       "      <td>166.927454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>Marvell's  ( MRVL )  Q4 Earnings and Revenues ...</td>\n",
       "      <td>https://www.zacks.com/stock/news/1877623/marve...</td>\n",
       "      <td>Marvell's (MRVL) Q4 top and bottom lines refle...</td>\n",
       "      <td>0.136708</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>164.490</td>\n",
       "      <td>163.17</td>\n",
       "      <td>165.55</td>\n",
       "      <td>162.10</td>\n",
       "      <td>80761684.0</td>\n",
       "      <td>710586.0</td>\n",
       "      <td>163.402599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>EPAM Shares Continue to Fall on Ukraine Crisis...</td>\n",
       "      <td>https://www.zacks.com/stock/news/1878525/epam-...</td>\n",
       "      <td>EPAM Systems' (EPAM) share price has plunged s...</td>\n",
       "      <td>-0.046687</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>163.360</td>\n",
       "      <td>159.30</td>\n",
       "      <td>165.02</td>\n",
       "      <td>159.04</td>\n",
       "      <td>92893526.0</td>\n",
       "      <td>803961.0</td>\n",
       "      <td>161.403790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                   Article Headline  \\\n",
       "0  2022-03-01  US stocks fall, oil tops $105 as Ukraine crisi...   \n",
       "1  2022-03-02  Rich Russians turn to luxury jewellery, watche...   \n",
       "2  2022-03-03    Are You an Investor Needing Some Calm Guidance?   \n",
       "3  2022-03-04  Marvell's  ( MRVL )  Q4 Earnings and Revenues ...   \n",
       "4  2022-03-07  EPAM Shares Continue to Fall on Ukraine Crisis...   \n",
       "\n",
       "                                         Article URL  \\\n",
       "0  https://www.aljazeera.com/economy/2022/3/1/us-...   \n",
       "1  https://www.aljazeera.com/economy/2022/3/2/ric...   \n",
       "2  https://www.fool.com/investing/2022/03/03/are-...   \n",
       "3  https://www.zacks.com/stock/news/1877623/marve...   \n",
       "4  https://www.zacks.com/stock/news/1878525/epam-...   \n",
       "\n",
       "                                        Article Text  overall_sentiment_score  \\\n",
       "0  A surge in oil sent shivers through risky asse...                -0.277460   \n",
       "1  With sanctions on Russia sending the ruble plu...                -0.118323   \n",
       "2                                         Read this.                -0.041040   \n",
       "3  Marvell's (MRVL) Q4 top and bottom lines refle...                 0.136708   \n",
       "4  EPAM Systems' (EPAM) share price has plunged s...                -0.046687   \n",
       "\n",
       "  overall_sentiment_label  Stock Open  Stock Close  Stock High  Stock Low  \\\n",
       "0        Somewhat-Bearish     164.695       163.20      166.60     161.97   \n",
       "1                 Neutral     164.390       166.56      167.36     162.95   \n",
       "2                 Neutral     168.470       166.23      168.91     165.55   \n",
       "3                 Neutral     164.490       163.17      165.55     162.10   \n",
       "4                 Neutral     163.360       159.30      165.02     159.04   \n",
       "\n",
       "       volume  num_trades   adj_close  \n",
       "0  79455454.0    701957.0  164.167482  \n",
       "1  76135254.0    631927.0  165.810466  \n",
       "2  73779442.0    622341.0  166.927454  \n",
       "3  80761684.0    710586.0  163.402599  \n",
       "4  92893526.0    803961.0  161.403790  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/stock_news_data_AAPL.csv')\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_ratio=0.8):\n",
    "    split_idx = int(len(df) * train_ratio)\n",
    "    train_df = df.iloc[:split_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[split_idx:].reset_index(drop=True)\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df= split_data(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "  \"\"\"\n",
    "  Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "  \"\"\"\n",
    "\n",
    "  model_name_or_path: str = field(\n",
    "      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "  )\n",
    "  config_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "  )\n",
    "  tokenizer_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "  )\n",
    "  cache_dir: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "  )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MultimodalDataTrainingArguments:\n",
    "  \"\"\"\n",
    "  Arguments pertaining to how we combine tabular features\n",
    "  Using `HfArgumentParser` we can turn this class\n",
    "  into argparse arguments to be able to specify them on\n",
    "  the command line.\n",
    "  \"\"\"\n",
    "\n",
    "  data_path: str = field(metadata={\n",
    "                            'help': 'the path to the csv file containing the dataset'\n",
    "                        })\n",
    "  column_info_path: str = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n",
    "  })\n",
    "\n",
    "  column_info: dict = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n",
    "                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n",
    "  })\n",
    "\n",
    "  categorical_encode_type: str = field(default='ohe',\n",
    "                                        metadata={\n",
    "                                            'help': 'sklearn encoder to use for categorical data',\n",
    "                                            'choices': ['ohe', 'binary', 'label', 'none']\n",
    "                                        })\n",
    "  numerical_transformer_method: str = field(default='yeo_johnson',\n",
    "                                            metadata={\n",
    "                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n",
    "                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n",
    "                                            })\n",
    "  task: str = field(default=\"classification\",\n",
    "                    metadata={\n",
    "                        \"help\": \"The downstream training task\",\n",
    "                        \"choices\": [\"classification\", \"regression\"]\n",
    "                    })\n",
    "\n",
    "  mlp_division: int = field(default=4,\n",
    "                            metadata={\n",
    "                                'help': 'the ratio of the number of '\n",
    "                                        'hidden dims in a current layer to the next MLP layer'\n",
    "                            })\n",
    "  combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
    "                                    metadata={\n",
    "                                        'help': 'method to combine categorical and numerical features, '\n",
    "                                                'see README for all the method'\n",
    "                                    })\n",
    "  mlp_dropout: float = field(default=0.1,\n",
    "                              metadata={\n",
    "                                'help': 'dropout ratio used for MLP layers'\n",
    "                              })\n",
    "  numerical_bn: bool = field(default=True,\n",
    "                              metadata={\n",
    "                                  'help': 'whether to use batchnorm on numerical features'\n",
    "                              })\n",
    "  use_simple_classifier: str = field(default=True,\n",
    "                                      metadata={\n",
    "                                          'help': 'whether to use single layer or MLP as final classifier'\n",
    "                                      })\n",
    "  mlp_act: str = field(default='relu',\n",
    "                        metadata={\n",
    "                            'help': 'the activation function to use for finetuning layers',\n",
    "                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n",
    "                        })\n",
    "  gating_beta: float = field(default=0.2,\n",
    "                              metadata={\n",
    "                                  'help': \"the beta hyperparameters used for gating tabular data \"\n",
    "                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n",
    "                              })\n",
    "\n",
    "  def __post_init__(self):\n",
    "      assert self.column_info != self.column_info_path\n",
    "      if self.column_info is None and self.column_info_path:\n",
    "          with open(self.column_info_path, 'r') as f:\n",
    "              self.column_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Article Headline', 'Article Text']\n",
    "cat_cols = ['Ticker']\n",
    "numerical_cols = ['Stock Open','Stock High','Stock Low','Stock Close','volume', 'adj_close']\n",
    "\n",
    "column_info_dict = {\n",
    "    'text_cols': text_cols,\n",
    "    'num_cols': numerical_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'label_col': 'overall_sentiment_label',\n",
    "    'label_list': ['Bearish', 'Neutral', 'Bullish', 'Somewhat-Bearish', 'Somewhat-Bullish'],\n",
    "}\n",
    "\n",
    "\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path='bert-base-uncased'\n",
    ")\n",
    "\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_path='data',\n",
    "    combine_feat_method='gating_on_cat_and_num_feats_then_sum',\n",
    "    column_info=column_info_dict,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs/model_name\",\n",
    "    logging_dir=\"./logs/runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    # evaluate_during_training=True,\n",
    "    logging_steps=25,\n",
    "    eval_steps=250\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified tokenizer:  bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path_or_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset, val_dataset, test_dataset \u001b[39m=\u001b[39m load_data_from_folder(\n\u001b[0;32m      2\u001b[0m     data_args\u001b[39m.\u001b[39;49mdata_path,\n\u001b[0;32m      3\u001b[0m     data_args\u001b[39m.\u001b[39;49mcolumn_info[\u001b[39m'\u001b[39;49m\u001b[39mtext_cols\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      4\u001b[0m     tokenizer,\n\u001b[0;32m      5\u001b[0m     label_col\u001b[39m=\u001b[39;49mdata_args\u001b[39m.\u001b[39;49mcolumn_info[\u001b[39m'\u001b[39;49m\u001b[39mlabel_col\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      6\u001b[0m     label_list\u001b[39m=\u001b[39;49mdata_args\u001b[39m.\u001b[39;49mcolumn_info[\u001b[39m'\u001b[39;49m\u001b[39mlabel_list\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      7\u001b[0m     numerical_cols\u001b[39m=\u001b[39;49mdata_args\u001b[39m.\u001b[39;49mcolumn_info[\u001b[39m'\u001b[39;49m\u001b[39mnum_cols\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      8\u001b[0m     sep_text_token_str\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49msep_token,\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\multimodal_transformers\\data\\load_data.py:202\u001b[0m, in \u001b[0;36mload_data_from_folder\u001b[1;34m(folder_path, text_cols, tokenizer, label_col, label_list, categorical_cols, numerical_cols, sep_text_token_str, categorical_encode_type, numerical_transformer_method, empty_text_values, replace_empty_text, max_token_length, debug, debug_dataset_size)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     val_df \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m load_train_val_test_helper(train_df, val_df, test_df,\n\u001b[0;32m    203\u001b[0m                                   text_cols, tokenizer, label_col,\n\u001b[0;32m    204\u001b[0m                                   label_list, categorical_cols, numerical_cols,\n\u001b[0;32m    205\u001b[0m                                   sep_text_token_str,\n\u001b[0;32m    206\u001b[0m                                   categorical_encode_type,\n\u001b[0;32m    207\u001b[0m                                   numerical_transformer_method,\n\u001b[0;32m    208\u001b[0m                                   empty_text_values,\n\u001b[0;32m    209\u001b[0m                                   replace_empty_text,\n\u001b[0;32m    210\u001b[0m                                   max_token_length,\n\u001b[0;32m    211\u001b[0m                                   debug,\n\u001b[0;32m    212\u001b[0m                                   debug_dataset_size)\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\multimodal_transformers\\data\\load_data.py:236\u001b[0m, in \u001b[0;36mload_train_val_test_helper\u001b[1;34m(train_df, val_df, test_df, text_cols, tokenizer, label_col, label_list, categorical_cols, numerical_cols, sep_text_token_str, categorical_encode_type, numerical_transformer_method, empty_text_values, replace_empty_text, max_token_length, debug, debug_dataset_size)\u001b[0m\n\u001b[0;32m    234\u001b[0m data_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    235\u001b[0m cat_feat_processor \u001b[39m=\u001b[39m CategoricalFeatures(data_df, categorical_cols, categorical_encode_type)\n\u001b[1;32m--> 236\u001b[0m vals \u001b[39m=\u001b[39m cat_feat_processor\u001b[39m.\u001b[39;49mfit_transform()\n\u001b[0;32m    237\u001b[0m cat_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(vals, columns\u001b[39m=\u001b[39mcat_feat_processor\u001b[39m.\u001b[39mfeat_names)\n\u001b[0;32m    238\u001b[0m data_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([data_df, cat_df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\multimodal_transformers\\data\\data_utils.py:78\u001b[0m, in \u001b[0;36mCategoricalFeatures.fit_transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_binarization()\n\u001b[0;32m     77\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mohe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_hot()\n\u001b[0;32m     79\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_feats]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\multimodal_transformers\\data\\data_utils.py:68\u001b[0m, in \u001b[0;36mCategoricalFeatures._one_hot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_one_hot\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     67\u001b[0m     ohe \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mOneHotEncoder(sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 68\u001b[0m     ohe\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcat_feats]\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ohe\u001b[39m.\u001b[39mget_feature_names_out(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_feats))\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m ohe\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_feats]\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3459\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
    "    data_args.data_path,\n",
    "    data_args.column_info['text_cols'],\n",
    "    tokenizer,\n",
    "    label_col=data_args.column_info['label_col'],\n",
    "    label_list=data_args.column_info['label_list'],\n",
    "    categorical_cols=data_args.column_info['cat_cols'],\n",
    "    numerical_cols=data_args.column_info['num_cols'],\n",
    "    sep_text_token_str=tokenizer.sep_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(np.unique(train_dataset.labels))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "tabular_config = TabularConfig(num_labels=num_labels,\n",
    "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
    "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
    "                               **vars(data_args))\n",
    "config.tabular_config = tabular_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithTabular.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "def calc_classification_metrics(p: EvalPrediction):\n",
    "  pred_labels = np.argmax(p.predictions, axis=1)\n",
    "  pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
    "  labels = p.label_ids\n",
    "  if len(np.unique(labels)) == 2:  # binary classification\n",
    "      roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
    "      precisions, recalls, thresholds = precision_recall_curve(labels,\n",
    "                                                                pred_scores)\n",
    "      fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "      fscore[np.isnan(fscore)] = 0\n",
    "      ix = np.argmax(fscore)\n",
    "      threshold = thresholds[ix].item()\n",
    "      pr_auc = auc(recalls, precisions)\n",
    "      tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
    "      result = {'roc_auc': roc_auc_pred_score,\n",
    "                'threshold': threshold,\n",
    "                'pr_auc': pr_auc,\n",
    "                'recall': recalls[ix].item(),\n",
    "                'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n",
    "                'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n",
    "                }\n",
    "  else:\n",
    "      acc = (pred_labels == labels).mean()\n",
    "      f1 = f1_score(y_true=labels, y_pred=pred_labels)\n",
    "      result = {\n",
    "          \"acc\": acc,\n",
    "          \"f1\": f1,\n",
    "          \"acc_and_f1\": (acc + f1) / 2,\n",
    "          \"mcc\": matthews_corrcoef(labels, pred_labels)\n",
    "      }\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=calc_classification_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/runs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci544_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
