{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "\n",
    "# 1. Install required packages\n",
    "# pip install pandas numpy ta-lib torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess the data using TA-Lib\n",
    "def preprocess_data(df):\n",
    "    df['SMA'] = talib.SMA(\n",
    "            df['Stock Close'], timeperiod=14)\n",
    "    df['EMA'] = talib.EMA(\n",
    "        df['Stock Close'], timeperiod=14)\n",
    "    df['RSI'] = talib.RSI(\n",
    "        df['Stock Close'], timeperiod=14)\n",
    "    df['MACD'], _, _ = talib.MACD(\n",
    "        df['Stock Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['ATR'] = talib.ATR(\n",
    "        df['Stock High'], df['Stock Low'], df['Stock Close'], timeperiod=14)\n",
    "    df[\"ADX\"] = talib.ADX(\n",
    "        df[\"Stock High\"].values, \n",
    "        df[\"Stock Low\"].values, \n",
    "        df[\"Stock Close\"].values\n",
    "        )\n",
    "    df.dropna(inplace=True)\n",
    "    print('data has been preprocessed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a custom Dataset class\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_text_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_text_length = max_text_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        text = row[\"Article Text\"]\n",
    "        ohlcv_data = row[[\"Stock Open\", \"Stock High\", \"Stock Low\", \"Stock Close\", \"volume\", \"SMA\", \"RSI\", \"ADX\", \"EMA\", \"ATR\", \"MACD\"]].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_text_length,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"ohlcv_data\": torch.tensor(ohlcv_data),\n",
    "            \"target\": torch.tensor(row[\"overall_sentiment_score\"].astype(np.float32)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define the multimodal model architecture\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, text_model_name, num_lstm_layers=1, hidden_size=128, dropout_rate=0.2):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(text_model_name)\n",
    "        self.lstm = nn.LSTM(input_size=11, hidden_size=hidden_size, num_layers=num_lstm_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(896, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, ohlcv_data):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = bert_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        ohlcv_data = ohlcv_data.unsqueeze(1)\n",
    "        lstm_output, _ = self.lstm(ohlcv_data)\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        combined = torch.cat([text_embedding, lstm_output], dim=1)\n",
    "        combined = self.dropout(combined)\n",
    "        output = self.fc(combined)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train the model (example)\n",
    "def train_model():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv(\"data/stock_news_data_AAPL.csv\")\n",
    "    # df = pd.read_csv(\"data/train.csv\")\n",
    "    df = preprocess_data(df)\n",
    "    # Initialize tokenizer, dataset, and dataloader\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    dataset = MultimodalDataset(df, tokenizer, max_text_length=128)\n",
    "    train_loader = data.DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = MultimodalModel(\"bert-base-uncased\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            ohlcv_data = batch[\"ohlcv_data\"]\n",
    "            target = batch[\"target\"]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, ohlcv_data)\n",
    "            \n",
    "            loss = criterion(outputs, target.clone().detach())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "# train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        ohlcv_data = batch[\"ohlcv_data\"].to(device)\n",
    "        sentiment_labels = batch[\"target\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, ohlcv_data)\n",
    "        loss = criterion(outputs, sentiment_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        correct_predictions += torch.sum(outputs == sentiment_labels)\n",
    "\n",
    "    accuracy = correct_predictions.double() / len(dataloader.dataset)\n",
    "    return epoch_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            ohlcv_data = batch[\"ohlcv_data\"].to(device)\n",
    "            sentiment_labels = batch[\"target\"].to(device)\n",
    "            alllabels.extend(sentiment_labels.cpu().numpy())\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, ohlcv_data)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            allpreds.extend(preds.cpu().numpy())\n",
    "            loss = criterion(outputs, sentiment_labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            correct_predictions += torch.sum(preds == sentiment_labels)\n",
    "\n",
    "    print(classification_report(alllabels, allpreds))\n",
    "    accuracy = correct_predictions.double() / len(dataloader.dataset)\n",
    "    return epoch_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Train Acc: {train_acc}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has been preprocessed\n",
      "data has been preprocessed\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = pd.read_csv(\"data/train.csv\"),pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_df = preprocess_data(train_df)\n",
    "val_df = preprocess_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d030828e05d6424fba09499bcf77c471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbala_n314ugx\\mambaforge\\envs\\csci544_2\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bbala_n314ugx\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6530c7e4888f4228b622bf820421ad6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7031c9937bdd406ab0dc67fcadbdbb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced7dceb073141ed94293d346b0fee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing BertModel: ['distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'pre_classifier.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'pre_classifier.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'classifier.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'classifier.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize tokenizer, dataset, and dataloader\n",
    "tokenizer = BertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "train_dataset = MultimodalDataset(train_df, tokenizer, max_text_length=128)\n",
    "val_dataset = MultimodalDataset(val_df, tokenizer, max_text_length=128)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalModel(\"distilbert-base-uncased-finetuned-sst-2-english\").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      3\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(model, train_dataloader, criterion, optimizer, device)\n\u001b[1;32m----> 4\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m evaluate(model, val_dataloader, criterion, device)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m, Train Acc: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m}\u001b[39;00m\u001b[39m, Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m, Val Acc: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m alllabels\u001b[39m.\u001b[39mextend(sentiment_labels\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     16\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask, ohlcv_data)\n\u001b[1;32m---> 17\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(outputs, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m allpreds\u001b[39m.\u001b[39mextend(preds\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     19\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, sentiment_labels)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci544_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
